{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dtata Augmentation And Creating CNN with Keras Tuner.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BRuGngxYOoE"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "datagen = ImageDataGenerator(rotation_range= 40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "img = load_img('/content/sample_data/cat with mask.jpg')\n",
        "x= img_to_array(img)\n",
        "x= x.reshape((1,)+x.shape)\n",
        "i=0\n",
        "for batch in datagen.flow(x, batch_size=1, save_to_dir='/content/sample_data/preview', save_prefix='cat', save_format='jpeg'):\n",
        "  i +=1\n",
        "  if(i>20):\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtMWSG5_dKRm"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShGQJrOnd44Q",
        "outputId": "9481faba-887f-42f0-a701-f1a1be3c59bc"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBZwz7JhjG0Q"
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZX-WvUAQjdjK",
        "outputId": "65d8c79e-cbeb-4a6e-b0e1-a9b3ea3e3f11"
      },
      "source": [
        "(train_images, train_labels), (test_images,test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_wFlVsQjpNK"
      },
      "source": [
        "train_images = train_images/255.0\n",
        "test_images = test_images/255.0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oLCge9fFwfL",
        "outputId": "aa46af25-475c-452e-ff38-e9e6f2152717"
      },
      "source": [
        "train_images[0].shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8iXEgmWF1YT"
      },
      "source": [
        "train_images = train_images.reshape(len(train_images), 28,28,1)\n",
        "test_images = test_images.reshape(len(test_images), 28,28,1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwWPc3GzGICM"
      },
      "source": [
        "def build_model(hp):\n",
        "  model = keras.Sequential([\n",
        "    keras.layers.Conv2D(\n",
        "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
        "        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n",
        "        activation='relu',\n",
        "        input_shape=(28,28,1)\n",
        "    ),\n",
        "    keras.layers.Conv2D(\n",
        "        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),\n",
        "        kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),\n",
        "        activation='relu'\n",
        "    ),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(\n",
        "        units=hp.Int('dense_1_unit', min_value=32, max_value=128, step=16),\n",
        "        activation='relu'\n",
        "    ),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2,1e-3])),\n",
        "              loss ='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6udXBH_XLzST"
      },
      "source": [
        "from kerastuner import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "papAqGjtOD-G"
      },
      "source": [
        "tuner_search = RandomSearch(build_model, objective='val_accuracy',max_trials=5, directory='output', project_name='mnist_fashion')"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5d8cNnMSyFn",
        "outputId": "9a8b1937-24bb-42c2-be2d-08c5b142a771"
      },
      "source": [
        "tuner_search.search(train_images, train_labels, epochs=3, validation_split=0.1)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 00m 41s]\n",
            "val_accuracy: 0.1054999977350235\n",
            "\n",
            "Best val_accuracy So Far: 0.909166693687439\n",
            "Total elapsed time: 00h 03m 03s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhrHO3dLU46x"
      },
      "source": [
        "model = tuner_search.get_best_models(num_models=1)[0]"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHVYBJeMl_Cv",
        "outputId": "d0b5640f-9240-49b7-9a59-d298aef438a6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 24, 24, 112)       2912      \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 22, 22, 32)        32288     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 15488)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 96)                1486944   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                970       \n",
            "=================================================================\n",
            "Total params: 1,523,114\n",
            "Trainable params: 1,523,114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6ts5RcFmBmV",
        "outputId": "eb77c474-5d14-476c-ba8b-8e3c0275c946"
      },
      "source": [
        "model.fit(train_images, train_labels, epochs=10, validation_split=0.1, initial_epoch=3)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/10\n",
            "1688/1688 [==============================] - 8s 5ms/step - loss: 0.1634 - accuracy: 0.9381 - val_loss: 0.2584 - val_accuracy: 0.9078\n",
            "Epoch 5/10\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.1266 - accuracy: 0.9520 - val_loss: 0.3065 - val_accuracy: 0.9067\n",
            "Epoch 6/10\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0973 - accuracy: 0.9634 - val_loss: 0.3110 - val_accuracy: 0.9158\n",
            "Epoch 7/10\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0747 - accuracy: 0.9716 - val_loss: 0.3339 - val_accuracy: 0.9158\n",
            "Epoch 8/10\n",
            "1688/1688 [==============================] - 8s 4ms/step - loss: 0.0579 - accuracy: 0.9781 - val_loss: 0.3610 - val_accuracy: 0.9122\n",
            "Epoch 9/10\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0446 - accuracy: 0.9838 - val_loss: 0.4285 - val_accuracy: 0.9137\n",
            "Epoch 10/10\n",
            "1688/1688 [==============================] - 7s 4ms/step - loss: 0.0375 - accuracy: 0.9860 - val_loss: 0.4346 - val_accuracy: 0.9135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd7b8835950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y0xDCrjmd24"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}